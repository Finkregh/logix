#!/usr/bin/python

# Juliano G. Martinez 
# based on : https://github.com/gleicon/restmq/blob/master/src/restmq/syslogd.py by Gleicon
# and another code made by Francisco Freire

import os
import re 
import sys 
import math
import time
import pycassa
import hashlib
from pyes import *
from twisted.python import log
from twisted.internet import reactor
from twisted.internet import threads
from twisted.python import threadable
from twisted.internet.protocol import DatagramProtocol

threadable.init(1)
reactor.suggestThreadPoolSize(64)

severity = ['emerg', 'alert', 'crit', 'err', 'warn', 'notice', 'info', 'debug']
facility = ['kern', 'user', 'mail', 'daemon', 'auth', 'syslog', 'lpr', 'news',
    'uucp', 'cron', 'authpriv', 'ftp', 'ntp', 'audit', 'alert', 'at', 'local0',
    'local1', 'local2', 'local3', 'local4', 'local5', 'local6', 'local7']

pool = pycassa.ConnectionPool('isr', ['10.50.0.181:9160'])
col_fam = pycassa.ColumnFamily(pool, 'rsyslog')
es_conn = ES('barney0002.email.locaweb.com.br:9500')
_doctype = "syslog"

fs_match = re.compile("<(.+)>(.*)", re.I)
class UDPSyslogServer(DatagramProtocol):
    def parseDatagram (self, datagram):
        parsed = {}
        parsed['line'] = datagram.strip()
        parsed['id'] = hashlib.sha256(parsed['line'])
        (fac, sev) = self._calc_lvl(parsed['line'])
        parsed['host'] = self.transport.getHost().host
        parsed['tstamp'] = time.time()
        parsed['facility'] = fac
        parsed['severity'] = sev
        parsed['tokens'] = self._tokenizer(parsed['line'], parsed['facility'])
        self.index(parsed)

    def _tokenizer(self, line, facility):
        pass

    def _create_index(self, _indexname):
        try:
            status = es_conn.status(_indexname)
            log.msg("Indexer status:%s" % status)
        except:
            es_conn.create_index(_indexname)
            time.sleep(1)
            status = iconn.status(_indexname)
            mappings = { u'line': {'boost': 1.0,
                                   'index': 'analyzed',
                                   'store': 'yes',
                                   'type': u'string',
                                   'term_vector': 'with_positions_offsets'},
                         u'line_id': {'boost': 1.0,
                                   'index': 'analyzed',
                                   'store': 'yes',
                                   'type': u'string',
                                   'term_vector': 'with_positions_offsets'},
                         u'log_file': {'boost': 1.0,
                                   'index': 'analyzed',
                                   'store': 'yes',
                                   'type': u'string',
                                   'term_vector': 'with_positions_offsets'},
                         u'date': {'store': 'yes',
                                    'type': u'date'}}
            time.sleep(1)
            status = es_conn.put_mapping(_doctype, mappings, _indexname)
    
    def index(self, parsed):
        self._create_index(parsed['facility'])
        log.msg(parsed)
        now = datetime.datetime.now()
        cassandra_key = "%d/%d/%d/%s-%d-Q0%d.log" % (now.year, now.month, now.day, parsed['facility'], now.hour, (now.minute/15))
        es_conn.index({'date': parsed['tstamp'], 'line': parsed['line'], 'log_file': cassandra_key, 'line_id': parsed['id']}, parsed['facility'], _doctype)
        col_fam.insert(cassandra_key, {parsed['id']: parsed['line']})

    def _calc_lvl(self, line):
        lvl = fs_match.split(line)
        if lvl and len(lvl) > 1:
            i = int(lvl[1])
            fac = int(math.floor(i / 8))
            sev = i - (fac * 8)
            return (facility[fac], severity[sev])
        return (None, None)

    def datagramReceived(self, datagram, address):
        self.transport.write(datagram, address)
        reactor.callInThread(self.parseDatagram, datagram)

if __name__ == '__main__':
    log.startLogging(sys.stdout)
    reactor.listenUDP(8000, UDPSyslogServer())
    reactor.run()
